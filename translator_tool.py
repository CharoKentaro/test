# tools/translator_tool.py

import streamlit as st
import google.generativeai as genai
from google.cloud import speech
from google.api_core.client_options import ClientOptions
from streamlit_mic_recorder import mic_recorder

# ===============================================================
# è£œåŠ©é–¢æ•° (calendar_tool.pyã‹ã‚‰ç¶™æ‰¿ã—ãŸã€ä¿¡é ¼ã§ãã‚‹ã‚³ãƒ¼ãƒ‰)
# ===============================================================
def transcribe_audio(audio_bytes, api_key):
    """Speech-to-Text APIã‚’ä½¿ç”¨ã—ã¦éŸ³å£°ãƒ‡ãƒ¼ã‚¿ã‚’æ—¥æœ¬èªãƒ†ã‚­ã‚¹ãƒˆã«å¤‰æ›ã™ã‚‹"""
    if not audio_bytes or not api_key:
        return None
    try:
        client_options = ClientOptions(api_key=api_key)
        client = speech.SpeechClient(client_options=client_options)
        audio = speech.RecognitionAudio(content=audio_bytes)
        # æ—¥æœ¬èªã®èãå–ã‚Šã«ç‰¹åŒ–
        config = speech.RecognitionConfig(language_code="ja-JP")
        response = client.recognize(config=config, audio=audio)
        if response.results:
            return response.results[0].alternatives[0].transcript
    except Exception as e:
        st.error(f"éŸ³å£°èªè­˜ã‚¨ãƒ©ãƒ¼: {e}")
    return None

# ===============================================================
# æ–°ã—ã„å°‚é–€å®¶ã®ä»•äº‹ï¼šç¿»è¨³
# ===============================================================
def translate_text_with_gemini(text_to_translate, api_key):
    """Geminiã‚’ä½¿ç”¨ã—ã¦ãƒ†ã‚­ã‚¹ãƒˆã‚’è‡ªç„¶ãªè‹±èªã«ç¿»è¨³ã™ã‚‹"""
    if not text_to_translate or not api_key:
        return None
    try:
        genai.configure(api_key=api_key)
        
        # ã¡ã‚ƒã‚æ§˜ã¨ã®è­°è«–ã§æ´—ç·´ã•ã›ãŸã€é­‚ã®ãƒ—ãƒ­ãƒ³ãƒ—ãƒˆ
        system_prompt = """
        ã‚ãªãŸã¯ã€è¨€èªã®å£ã‚’ä¹—ã‚Šè¶Šãˆã‚‹æ‰‹åŠ©ã‘ã‚’ã™ã‚‹ã€éå¸¸ã«å„ªç§€ãªç¿»è¨³ã‚¢ã‚·ã‚¹ã‚¿ãƒ³ãƒˆã§ã™ã€‚
        ãƒ¦ãƒ¼ã‚¶ãƒ¼ã‹ã‚‰æ¸¡ã•ã‚ŒãŸæ—¥æœ¬èªã®ãƒ†ã‚­ã‚¹ãƒˆã‚’ã€æµ·å¤–ã®è¦ªã—ã„å‹äººã¨ã®ä¼šè©±ã§ä½¿ã‚ã‚Œã‚‹ã‚ˆã†ãªã€è‡ªç„¶ã§ã€ã‚«ã‚¸ãƒ¥ã‚¢ãƒ«ã§ã‚ã‚ŠãªãŒã‚‰ç¤¼å„€æ­£ã—ãã€ãã—ã¦ãƒ•ãƒ¬ãƒ³ãƒ‰ãƒªãƒ¼ãªè‹±èªã«ç¿»è¨³ã—ã¦ãã ã•ã„ã€‚
        - éå¸¸ã«ç¡¬ã„è¡¨ç¾ã‚„ã€ãƒ“ã‚¸ãƒã‚¹æ–‡æ›¸ã®ã‚ˆã†ãªç¿»è¨³ã¯é¿ã‘ã¦ãã ã•ã„ã€‚
        - ç¿»è¨³å¾Œã®è‹±èªãƒ†ã‚­ã‚¹ãƒˆã®ã¿ã‚’å›ç­”ã—ã¦ãã ã•ã„ã€‚ä»–ã®è¨€è‘‰ã¯ä¸€åˆ‡å«ã‚ãªã„ã§ãã ã•ã„ã€‚
        """
        model = genai.GenerativeModel('gemini-1.5-flash-latest', system_instruction=system_prompt)
        response = model.generate_content(text_to_translate)
        return response.text.strip()
    except Exception as e:
        st.error(f"ç¿»è¨³ã‚¨ãƒ©ãƒ¼: {e}")
    return None

# ===============================================================
# å°‚é–€å®¶ã®ãƒ¡ã‚¤ãƒ³ã®ä»•äº‹ (å¸ä»¤å¡” app.py ã‹ã‚‰å‘¼ã³å‡ºã•ã‚Œã‚‹)
# ===============================================================
def show_tool(gemini_api_key, speech_api_key):
    st.header("ğŸ¤ ãƒ•ãƒ¬ãƒ³ãƒ‰ãƒªãƒ¼ç¿»è¨³ãƒ„ãƒ¼ãƒ«", divider='rainbow')

    # --- çŠ¶æ…‹ç®¡ç†ã®åˆæœŸåŒ– (ç§ãŸã¡ã®å¡æ™º) ---
    if "translation_results" not in st.session_state:
        st.session_state.translation_results = []
    # ã€Œã“ã ã¾ã€é˜²æ­¢ç”¨ã®IDè¨˜æ†¶å ´æ‰€
    if "translator_last_mic_id" not in st.session_state:
        st.session_state.translator_last_mic_id = None

    # --- UIã‚¦ã‚£ã‚¸ã‚§ãƒƒãƒˆã®è¡¨ç¤º ---
    st.info("ãƒã‚¤ã‚¯ã§æ—¥æœ¬èªã‚’è©±ã™ã‹ã€ãƒ†ã‚­ã‚¹ãƒˆãƒœãƒƒã‚¯ã‚¹ã«å…¥åŠ›ã—ã¦ãã ã•ã„ã€‚è‡ªç„¶ãªè‹±èªã«ç¿»è¨³ã—ã¾ã™ã€‚")

    # éŸ³å£°å…¥åŠ›ã¨ãƒ†ã‚­ã‚¹ãƒˆå…¥åŠ›ï¼ˆãƒ‡ãƒ¥ã‚¢ãƒ«å…¥åŠ›æ–¹å¼ï¼‰
    col1, col2 = st.columns([1, 2])
    with col1:
        audio_info = mic_recorder(
            start_prompt="ğŸ¤ è©±ã—å§‹ã‚ã‚‹",
            stop_prompt="â¹ï¸ ç¿»è¨³ã™ã‚‹",
            key='translator_mic'
        )
    with col2:
        text_prompt = st.text_input("ã¾ãŸã¯ã€ã“ã“ã«æ—¥æœ¬èªã‚’å…¥åŠ›...", key="translator_text")

    # --- çµæœè¡¨ç¤ºã‚¨ãƒªã‚¢ ---
    if st.session_state.translation_results:
        st.write("---")
        for i, result in enumerate(reversed(st.session_state.translation_results)): # æ–°ã—ã„ã‚‚ã®ãŒä¸Šã«ãã‚‹ã‚ˆã†ã«
            with st.container(border=True):
                st.caption(f"ç¿»è¨³ {len(st.session_state.translation_results) - i}")
                st.markdown(f"**ğŸ‡¯ğŸ‡µ å…¥åŠ› (æ—¥æœ¬èª):**\n{result['original']}")
                st.markdown(f"**ğŸ‡ºğŸ‡¸ ç¿»è¨³ (è‹±èª):**\n{result['translated']}")
        if st.button("ç¿»è¨³å±¥æ­´ã‚’ã‚¯ãƒªã‚¢", key="clear_history"):
            st.session_state.translation_results = []
            st.rerun()


    # --- å…¥åŠ›ãŒã‚ã£ãŸå ´åˆã®ã€ä¸€åº¦ãã‚Šã®ã€å‡¦ç†ãƒ•ãƒ­ãƒ¼ ---
    japanese_text = None
    source = None # å…¥åŠ›ã‚½ãƒ¼ã‚¹ã‚’è¨˜éŒ²

    # éŸ³å£°å…¥åŠ›ãŒã‚ã£ãŸå ´åˆ
    if audio_info and audio_info['id'] != st.session_state.translator_last_mic_id:
        st.session_state.translator_last_mic_id = audio_info['id']
        if not speech_api_key:
            st.error("ã‚µã‚¤ãƒ‰ãƒãƒ¼ã§Speech-to-Text APIã‚­ãƒ¼ã‚’è¨­å®šã—ã¦ãã ã•ã„ã€‚")
        else:
            with st.spinner("éŸ³å£°ã‚’æ—¥æœ¬èªã«å¤‰æ›ä¸­..."):
                japanese_text = transcribe_audio(audio_info['bytes'], speech_api_key)
                source = "mic"

    # ãƒ†ã‚­ã‚¹ãƒˆå…¥åŠ›ãŒã‚ã£ãŸå ´åˆ
    elif text_prompt:
        japanese_text = text_prompt
        source = "text"

    # --- ç¿»è¨³å‡¦ç†ã®å®Ÿè¡Œ ---
    if japanese_text:
        if not gemini_api_key:
            st.error("ã‚µã‚¤ãƒ‰ãƒãƒ¼ã§Gemini APIã‚­ãƒ¼ã‚’è¨­å®šã—ã¦ãã ã•ã„ã€‚")
        else:
            with st.spinner("AIãŒæœ€é©ãªè‹±èªã‚’è€ƒãˆã¦ã„ã¾ã™..."):
                translated_text = translate_text_with_gemini(japanese_text, gemini_api_key)

            if translated_text:
                # ç¿»è¨³çµæœã‚’ã‚»ãƒƒã‚·ãƒ§ãƒ³çŠ¶æ…‹ã«ä¿å­˜
                st.session_state.translation_results.append({
                    "original": japanese_text,
                    "translated": translated_text
                })
                # ãƒ†ã‚­ã‚¹ãƒˆå…¥åŠ›æ¬„ã‚’ã‚¯ãƒªã‚¢ã™ã‚‹ãŸã‚ã«rerunã‚’å‘¼ã¶
                # ã“ã®ã‚·ãƒ³ãƒ—ãƒ«ãªä½¿ã„æ–¹ãªã‚‰ã€ç§ãŸã¡ã®ç®¡ç†ä¸‹ã«ç½®ã‘ã‚‹
                st.rerun()
            else:
                st.warning("ç¿»è¨³ã«å¤±æ•—ã—ã¾ã—ãŸã€‚ã‚‚ã†ä¸€åº¦ãŠè©¦ã—ãã ã•ã„ã€‚")
